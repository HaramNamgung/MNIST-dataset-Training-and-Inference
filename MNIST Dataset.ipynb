{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f4f32-47de-4ad2-aeac-28986e5ea1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 모듈과 라이브러리 import하기\n",
    "\n",
    "# nn: 신경망 만들 때 쓰는 기본 도구들 (레이어, 활성화 함수 등)\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch: 텐서 다루고 GPU 쓸 수 있게 해준다\n",
    "import torch \n",
    "\n",
    "# datasets: 유명한 데이터셋 쉽게 다운받게 해줌\n",
    "from torchvision import datasets\n",
    "\n",
    "# transforms: 이미지를 모델이 먹을 수 있게 변환해줌(텐서로 변환하고 정규화)\n",
    "from torchvision import transforms\n",
    "\n",
    "# DataLoader: 데이터를 불러오는 애\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# numpy: 숫자 계산할 때 쓰는 라이브러리\n",
    "import numpy as np\n",
    "\n",
    "# optim: 모델을 학습시키는 최적화 알고리즘들 (경사하강법 등)\n",
    "import torch.optim as optim \n",
    "\n",
    "# plt: 그래프 그리고 이미지 보여주는 애\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344c0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터셋 다운로드 및 불러오기\n",
    "\n",
    "# 데이터셋을 저장할 경로 넣을 변수\n",
    "download_root = 'MNIST_data/'\n",
    "\n",
    "# 학습용 데이터셋\n",
    "dataset1 = datasets.MNIST(root=download_root, \n",
    "                          train = True, \n",
    "                          # 이미지를 PyTorch FloatTensor로 변환\n",
    "                          # 왜냐면 딥러닝 모델은 텐서 형태의 데이터만 알아먹음!\n",
    "                          # 픽셀값을 0~1 범위로 정규화하기!\n",
    "                          transform = transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "# 테스트용 데이터셋\n",
    "dataset2 = datasets.MNIST(root=download_root,\n",
    "                            # 학습용이 아니므로 이번에는 False!\n",
    "                            train = False, \n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d06c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성하기\n",
    "\n",
    "# 첫번째 모델\n",
    "# fully connected layer \n",
    "\n",
    "class FullyConnectNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 부모 클래스의 생성자를 호출 -> 부모가 가진 기능들 쓸 수 있도록!\n",
    "        super(FullyConnectNN, self).__init__()\n",
    "        # 레이어 정의하기\n",
    "        # 28x28 크기의 이미지를 1차원 벡터(784)로 바꿈\n",
    "        # 은닉층의 뉴런 개수는 512개로 설정!\n",
    "        # 첫번째 은닉층\n",
    "        self.fc1 = nn.Linear(28*28, 512) # 입력층 -> 은닉층\n",
    "        # 두번째 은닉층\n",
    "        self.fc2 = nn.Linear(512, 512) # 은닉층 -> 은닉층\n",
    "        self.fc3 = nn.Linear(512, 10)  # 은닉층 -> 출력층 (0~9 숫자 분류)\n",
    "        # 활성화 함수로 ReLU 사용\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    # forward 메서드: 데이터가 모델을 통과할 때 어떻게 변하는지 정의\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc1(x) # 첫번째 레이어 통과\n",
    "        x2 = self.relu(x1) # ReLU 활성화 함수 적용\n",
    "        x3 = self.fc2(x2) # 두번째 레이어 통과\n",
    "        x4 = self.relu(x3) # ReLU 활성화 함수 적용\n",
    "        x5 = self.fc3(x4) # 세번째 레이어 통과\n",
    "        return x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0024192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#두번째 모델\n",
    "# 합성곱 신경망 (Convolutional Neural Network, CNN)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫번째 합성곱층: 입력 채널 1개(흑백), 출력 채널 32개, 커널 크기 3x3\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # 두번째 합성곱층: 입력 채널 32개, 출력 채널 64개, 커널 크기 3x3\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # 세번째 합성곱층: 입력 채널 64개, 출력 채널 128개, 커널 크기 3x3\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        # 풀링층: 2x2 크기의 맥스 풀링\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # 완전 연결층: 입력 뉴런 128*3*3, 출력 뉴런 10 (0~9 숫자 분류)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 10)\n",
    "        # 활성화 함수로 ReLU 사용\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # 첫번째 합성곱층 통과\n",
    "        x = self.relu(x) # ReLU 활성화 함수 적용\n",
    "        x = self.pool(x) # 풀링층 통과\n",
    "\n",
    "        x = self.conv2(x) # 두번째 합성곱층 통과\n",
    "        x = self.relu(x) # ReLU 활성화 함수 적용\n",
    "        x = self.pool(x) # 풀링층 통과\n",
    "\n",
    "        x = self.conv3(x) # 세번째 합성곱층 통과\n",
    "        x = self.relu(x) # ReLU 활성화 함수 적용\n",
    "        x = self.pool(x) # 풀링층 통과\n",
    "\n",
    "        x = x.view(-1, 128 * 3 * 3) # fully connected layer에 넣기 위해 1차원 벡터로 쫙쫙 피기\n",
    "        x = self.fc1(x) # 완전 연결층 통과\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca13453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch 사이즈 설정하기\n",
    "batch = 100\n",
    "# DataLoader로 데이터셋 불러오기\n",
    "train_Loader = DataLoader(dataset=dataset1, batch_size = batch, shuffle = True)\n",
    "test_Loader = DataLoader(dataset=dataset2, batch_size = batch, shuffle = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
